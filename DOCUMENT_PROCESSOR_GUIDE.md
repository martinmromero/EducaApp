# üìö Document Processor - Gu√≠a de Uso

## ‚úÖ Instalaci√≥n Completada

Se ha instalado exitosamente el **Stack Completo** de procesamiento de documentos:

- ‚úÖ **PyMuPDF** 1.26.5 (reemplaza a PyPDF2)
- ‚úÖ **pdfplumber** 0.11.7
- ‚úÖ **tiktoken** 0.12.0
- ‚úÖ **markdownify** 1.2.0
- ‚úÖ **python-docx** 0.8.11
- ‚úÖ **python-pptx** 0.6.23

**PyPDF2** ha sido desinstalado y reemplazado por PyMuPDF (superior en todos los aspectos).

---

## üéØ Archivos Creados

| Archivo | Descripci√≥n |
|---------|-------------|
| `document_processor.py` | M√≥dulo principal con clase `DocumentProcessor` |
| `example_document_processor.py` | Ejemplos completos de uso |
| `requirements.txt` | Actualizado con nuevas dependencias |
| `requirements_document_processing.txt` | Versi√≥n detallada con comentarios |
| `DOCUMENT_PROCESSING_ANALYSIS.md` | An√°lisis completo y recomendaciones |
| `INSTALL_DOCUMENT_PROCESSING.ps1` | Scripts de instalaci√≥n |

---

## üöÄ Inicio R√°pido

### 1. Importar el m√≥dulo

```python
from document_processor import DocumentProcessor, process_document

# Crear procesador
processor = DocumentProcessor()
```

### 2. Procesar un PDF

```python
# Autom√°tico (detecta TOC, limpia headers/footers)
result = processor.process_pdf("mi_documento.pdf")

# Ver resumen
print(processor.get_stats_summary(result))

# Acceder a cap√≠tulos
for chapter in result['chapters']:
    print(f"{chapter['title']}: {chapter['tokens']} tokens")
```

### 3. Contar tokens (ESENCIAL para IA)

```python
# Contar tokens de un texto
tokens = processor.count_tokens("Tu texto aqu√≠")
print(f"Tokens (GPT-4): {tokens}")

# Contar tokens de todo un documento
tokens_totales = quick_token_count("documento.pdf")
```

### 4. Dividir por l√≠mite de tokens

```python
# Dividir texto largo para enviar a IA
texto_largo = "..." # Tu texto
chunks = processor.split_by_token_limit(texto_largo, max_tokens=4000)

# Cada chunk tiene m√°ximo 4000 tokens
for i, chunk in enumerate(chunks):
    print(f"Chunk {i+1}: {processor.count_tokens(chunk)} tokens")
```

---

## üìñ Funcionalidades Principales

### A) Procesamiento de PDFs

```python
result = processor.process_pdf(
    file_path="documento.pdf",
    remove_headers=True,      # Elimina headers repetitivos
    remove_footers=True,      # Elimina footers y n√∫meros de p√°gina
    extract_toc=True          # Extrae tabla de contenidos si existe
)

# Estructura del resultado:
# {
#     'metadata': {'title': str, 'author': str, 'total_pages': int},
#     'toc': [{'level': int, 'title': str, 'page': int}],
#     'chapters': [{'title': str, 'content': str, 'tokens': int, 'pages': [int]}],
#     'stats': {'total_tokens': int, 'removed_headers': int, ...}
# }
```

**Ventajas de PyMuPDF:**
- ‚úÖ Extrae TOC (tabla de contenidos) directamente
- ‚úÖ Detecta estructura jer√°rquica autom√°ticamente
- ‚úÖ Mejor manejo de PDFs complejos (multi-columna, tablas)
- ‚úÖ M√°s r√°pido que PyPDF2

### B) Procesamiento de DOCX

```python
result = processor.process_docx("documento.docx")

# Detecta autom√°ticamente:
# - Headings (T√≠tulo 1, 2, 3...)
# - Organiza por cap√≠tulos seg√∫n estilos
# - Cuenta tokens por secci√≥n
```

### C) Procesamiento de PPTX

```python
result = processor.process_pptx("presentacion.pptx")

# Extrae:
# - Texto de cada slide
# - T√≠tulos de slides
# - Tokens por slide
```

### D) Detecci√≥n y Limpieza de Texto Repetitivo

```python
# Autom√°tico en PDFs:
# - Detecta headers que se repiten en >70% de p√°ginas
# - Elimina footers repetitivos
# - Quita n√∫meros de p√°gina solitarios

# Manual para cualquier texto:
texto_limpio = processor.optimize_for_ai(
    text=texto_sucio,
    remove_extra_whitespace=True,  # Elimina espacios/saltos extras
    remove_urls=True,              # Quita URLs
    remove_emails=True             # Quita emails
)
```

### E) Conteo de Tokens (CR√çTICO para IA)

```python
# Usa tiktoken para conteo exacto (GPT-4 encoding)
tokens = processor.count_tokens("Tu texto")

# Divisi√≥n inteligente por l√≠mite
chunks = processor.split_by_token_limit(
    text=texto_largo,
    max_tokens=4000  # L√≠mite de contexto de la IA
)
```

### F) Exportar Resultados

```python
# Guardar como JSON
processor.export_to_json(result, "documento_procesado.json")

# Ver resumen en consola
print(processor.get_stats_summary(result))
```

---

## üí° Casos de Uso

### 1. Preparar documento para GPT-4

```python
# Flujo completo
processor = DocumentProcessor()

# 1. Procesar
result = processor.process_pdf("tesis.pdf")

# 2. Seleccionar cap√≠tulo relevante
capitulo = result['chapters'][0]

# 3. Verificar l√≠mite
LIMITE_GPT4 = 8000
if capitulo['tokens'] > LIMITE_GPT4:
    # Dividir en chunks
    chunks = processor.split_by_token_limit(capitulo['content'], LIMITE_GPT4)
else:
    chunks = [capitulo['content']]

# 4. Optimizar
for chunk in chunks:
    chunk_optimizado = processor.optimize_for_ai(chunk)
    # Enviar a API de OpenAI...
```

### 2. Analizar m√∫ltiples documentos

```python
import os

archivos = ["doc1.pdf", "doc2.docx", "doc3.pptx"]
total_tokens = 0

for archivo in archivos:
    result = process_document(archivo)  # Detecta formato autom√°ticamente
    tokens = result['stats']['total_tokens']
    total_tokens += tokens
    print(f"{archivo}: {tokens} tokens")

print(f"Total: {total_tokens} tokens")
```

### 3. Extraer solo cap√≠tulos espec√≠ficos

```python
result = processor.process_pdf("libro.pdf")

# Filtrar cap√≠tulos por palabra clave
capitulos_relevantes = [
    ch for ch in result['chapters']
    if 'metodolog√≠a' in ch['title'].lower()
]

for ch in capitulos_relevantes:
    print(f"{ch['title']}: {ch['tokens']} tokens")
    print(ch['content'][:200])  # Preview
```

### 4. Calcular costo de procesamiento con IA

```python
# GPT-4: $0.03 por 1K tokens (input)
tokens = quick_token_count("documento_grande.pdf")
costo_usd = (tokens / 1000) * 0.03

print(f"Tokens: {tokens:,}")
print(f"Costo estimado (GPT-4): ${costo_usd:.2f}")
```

---

## üß™ Probar el M√≥dulo

Ejecut√° el ejemplo completo:

```powershell
# Activar entorno
.\.venv\Scripts\Activate.ps1

# Ejecutar demostraci√≥n
python example_document_processor.py
```

Esto:
1. ‚úÖ Crea un PDF de prueba
2. ‚úÖ Procesa con detecci√≥n de TOC
3. ‚úÖ Demuestra conteo de tokens
4. ‚úÖ Muestra divisi√≥n por l√≠mite
5. ‚úÖ Optimiza texto
6. ‚úÖ Simula flujo para IA

Archivos generados:
- `ejemplo_documento.pdf`
- `ejemplo_resultado.json`

---

## üìä Comparaci√≥n: Antes vs Despu√©s

| Aspecto | PyPDF2 (Antes) | PyMuPDF (Ahora) |
|---------|---------------|-----------------|
| Extracci√≥n TOC | ‚ùå No | ‚úÖ S√≠, nativo |
| Detecci√≥n de estructura | ‚ùå Manual | ‚úÖ Autom√°tica |
| Headers/Footers | ‚ùå No detecta | ‚úÖ Detecta con pdfplumber |
| PDFs complejos | ‚ö†Ô∏è Problemas | ‚úÖ Excelente |
| Velocidad | ‚ö†Ô∏è Lento | ‚úÖ R√°pido |
| Conteo de tokens | ‚ùå No | ‚úÖ tiktoken integrado |

---

## üîß Integraci√≥n con Django (EducaApp)

### Opci√≥n 1: Agregar a `material/ia_processor.py`

```python
# En material/ia_processor.py
from document_processor import DocumentProcessor

class IAProcessor:
    def __init__(self):
        self.doc_processor = DocumentProcessor()
    
    def procesar_contenido_documento(self, archivo_path):
        """Procesa documento subido por usuario."""
        result = self.doc_processor.process_pdf(archivo_path)
        
        # Guardar en BD o retornar para an√°lisis
        return {
            'capitulos': result['chapters'],
            'tokens_totales': result['stats']['total_tokens']
        }
```

### Opci√≥n 2: Vista para procesar documentos

```python
# En material/views.py
from document_processor import process_document
from django.http import JsonResponse

def procesar_documento_view(request):
    if request.method == 'POST' and request.FILES.get('documento'):
        archivo = request.FILES['documento']
        
        # Guardar temporalmente
        file_path = f'/tmp/{archivo.name}'
        with open(file_path, 'wb') as f:
            for chunk in archivo.chunks():
                f.write(chunk)
        
        # Procesar
        result = process_document(file_path)
        
        return JsonResponse({
            'success': True,
            'metadata': result['metadata'],
            'capitulos': len(result['chapters']),
            'tokens': result['stats']['total_tokens']
        })
```

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Cambiar encoding de tokens

```python
# Por defecto: cl100k_base (GPT-4)
processor = DocumentProcessor(encoding_name="cl100k_base")

# Otros encodings:
# - "p50k_base" (GPT-3, Codex)
# - "r50k_base" (GPT-3 legacy)
```

### Ajustar detecci√≥n de headers/footers

```python
# Umbral: % de p√°ginas donde debe aparecer para ser "repetitivo"
# Por defecto: 0.7 (70%)

# Modificar en _detect_repetitive_text():
headers, footers = self._detect_repetitive_text(
    file_path,
    threshold=0.8  # M√°s estricto: solo si aparece en 80%+
)
```

---

## üìö Recursos

- **PyMuPDF Docs**: https://pymupdf.readthedocs.io/
- **pdfplumber**: https://github.com/jsvine/pdfplumber
- **tiktoken**: https://github.com/openai/tiktoken
- **OpenAI Pricing**: https://openai.com/pricing

---

## üÜò Troubleshooting

### Error: "No module named 'fitz'"
```powershell
pip uninstall PyMuPDF -y
pip install PyMuPDF
```

### Error: PDFs sin TOC
```python
# Si el PDF no tiene TOC, el procesador autom√°ticamente:
# - Extrae todo el texto limpio
# - Lo devuelve como un solo "cap√≠tulo"
result = processor.process_pdf("sin_toc.pdf")
print(result['chapters'][0]['title'])  # "Documento completo"
```

### Optimizar velocidad
```python
# Para PDFs muy grandes, samplear menos p√°ginas en detecci√≥n:
# Modificar en _detect_repetitive_text():
for page in pdf.pages[:5]:  # Solo primeras 5 en vez de 10
    ...
```

---

## ‚úÖ Checklist de Uso

- [x] Instalaci√≥n completada (Stack Completo)
- [x] PyPDF2 desinstalado
- [x] `requirements.txt` actualizado
- [x] M√≥dulo `document_processor.py` creado
- [x] Ejemplos ejecutados exitosamente
- [ ] Integrado en tu proyecto Django (opcional)
- [ ] Probado con tus propios documentos

---

## üéØ Pr√≥ximos Pasos Sugeridos

1. **Probar con tus propios PDFs**
   ```python
   result = process_document("tu_documento.pdf")
   print(processor.get_stats_summary(result))
   ```

2. **Integrar con EducaApp**
   - Agregar vista para subir documentos
   - Procesar y extraer preguntas autom√°ticamente
   - Usar tokens para fragmentar contenido largo

3. **Optimizar para costos de IA**
   - Siempre contar tokens antes de enviar
   - Dividir documentos grandes en chunks
   - Limpiar texto repetitivo

---

**¬øDudas o necesit√°s ayuda?**
- Revis√° `example_document_processor.py` para ver todos los casos de uso
- Ejecut√° los ejemplos paso a paso
- Consult√° la documentaci√≥n en los archivos creados

**Listo para usar** ‚úÖ
