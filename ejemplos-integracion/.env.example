# ========================================
# CONFIGURACIÓN DE EJEMPLO PARA BACKEND
# ========================================
# Copiar este archivo como .env y ajustar los valores

# ----------------------------------------
# SERVIDOR BACKEND
# ----------------------------------------
PORT=3000
NODE_ENV=development

# ----------------------------------------
# OLLAMA (Servidor de IA)
# ----------------------------------------
# IP o hostname del servidor Ollama
OLLAMA_HOST=localhost
# OLLAMA_HOST=192.168.12.236  # Ejemplo: servidor en red local

# Puerto de Ollama (default: 11434)
OLLAMA_PORT=11434

# Modelo a utilizar
OLLAMA_MODEL=llama3.1:8b
# Opciones:
#   - llama3.1:8b (General, 8B parámetros)
#   - gemma3:4b (General, más ligero)
#   - medgemma-4b-it-Q6_K:latest (Especializado en medicina)
#   - mistral:7b (General, bueno para español)

# ----------------------------------------
# PARÁMETROS DE GENERACIÓN
# ----------------------------------------
# Temperatura: Controla aleatoriedad (0.0 = determinista, 1.0 = creativo)
AI_TEMPERATURE=0.7

# Máximo de tokens a generar
AI_MAX_TOKENS=150

# Top-p: Nucleus sampling (0.0 - 1.0)
AI_TOP_P=0.9

# ----------------------------------------
# BASE DE DATOS (PostgreSQL)
# ----------------------------------------
DB_HOST=localhost
DB_PORT=5432
DB_NAME=simulador_pacientes
DB_USER=postgres
DB_PASSWORD=tu_password_seguro

# ----------------------------------------
# SEGURIDAD
# ----------------------------------------
# Secreto para sesiones (cambiar en producción)
SESSION_SECRET=cambiar_esto_en_produccion_usar_string_aleatorio_largo

# ----------------------------------------
# CORS (Si frontend está en otro dominio/puerto)
# ----------------------------------------
# Orígenes permitidos (separados por coma)
# CORS_ORIGINS=http://localhost:8080,https://tu-dominio.com

# ----------------------------------------
# LOGS Y DEBUG
# ----------------------------------------
# Nivel de logs (debug, info, warn, error)
LOG_LEVEL=info

# Habilitar logs detallados de IA
# AI_DEBUG=true
